# üöÄ AI Prompt Debugger - Getting Started

Welcome! This guide will get you up and running in 5 minutes.

## üì¶ Installation

### Prerequisites
- Python 3.9 or higher
- pip (Python package manager)

### Setup Steps

1. **Navigate to the project directory**
```bash
cd ai-prompt-debugger
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

That's it! You're ready to go.

## üéØ Quick Test

### 1. Run the Interactive Demo

The best way to see all features is to run the demo:

```bash
python demo.py
```

This will walk you through 7 different demonstrations showing all capabilities.

### 2. Analyze Your First Prompt

Try the CLI:

```bash
python -m src.cli.main analyze "Write some code to process data"
```

You should see output like:
```
üìä Analysis Results
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Overall Quality: 34.2/100
Grade: F

Core Metrics
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Metric            ‚îÇ Score    ‚îÇ Status       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Clarity           ‚îÇ 45.3/100 ‚îÇ ‚ö† Needs Work ‚îÇ
‚îÇ Token Efficiency  ‚îÇ 78.5%    ‚îÇ ‚ö† Can Improve‚îÇ
‚îÇ Success Prob.     ‚îÇ 28.1%    ‚îÇ ‚ö† Uncertain  ‚îÇ
‚îÇ Security Score    ‚îÇ 100.0/100‚îÇ ‚úì Safe       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

MEDIUM ISSUES (3):
1. Vague term detected: 'some'
   ...
```

## üìù Basic Usage Examples

### Example 1: Analyze a File

Create a file `my_prompt.txt`:
```
Create a REST API endpoint for user login.

Requirements:
- Accept email and password
- Return JWT token
- Handle errors
```

Analyze it:
```bash
python -m src.cli.main analyze --file my_prompt.txt
```

### Example 2: Compare Two Prompts

Create `v1.txt`:
```
Write code for user authentication.
```

Create `v2.txt`:
```
Create a Python function for user authentication.

Requirements:
- Input: username (str), password (str)
- Output: True if valid, False otherwise
- Use bcrypt for password hashing
- Include error handling

Example:
authenticate("john@example.com", "secret123") -> True
```

Compare them:
```bash
python -m src.cli.main compare v1.txt v2.txt
```

### Example 3: Interactive Mode

Start an interactive session:
```bash
python -m src.cli.main interactive
```

Then paste or type your prompts. Press Ctrl+D (Linux/Mac) or Ctrl+Z (Windows) to analyze.

## üêç Using the Python API

Create a file `test_api.py`:

```python
from src.core.debugger import PromptDebugger

# Initialize
debugger = PromptDebugger()

# Your prompt
prompt = """
Create a function to calculate fibonacci numbers.
Input: n (integer)
Output: list of first n fibonacci numbers
"""

# Analyze
result = debugger.analyze(prompt)

# Print results
print(f"Quality Score: {result.overall_quality_score}/100")
print(f"Grade: {result.overall_grade}")
print(f"Total Issues: {len(result.issues)}")
print(f"Success Probability: {result.predictions.success_probability}%")

# Show issues
for issue in result.issues:
    print(f"\n[{issue.severity.value}] {issue.title}")
    print(f"  {issue.description}")
```

Run it:
```bash
python test_api.py
```

## üé® Understanding the Output

### Quality Scores Explained

- **Overall Quality (0-100)**: Combined score from all analyzers
  - 90-100: Excellent (Grade A) - Production ready
  - 80-89: Good (Grade B) - Minor improvements
  - 70-79: Fair (Grade C) - Needs work
  - 60-69: Poor (Grade D) - Significant issues
  - <60: Failing (Grade F) - Major problems

- **Clarity Score**: How clear and unambiguous your prompt is
- **Token Efficiency**: Percentage of non-wasted tokens
- **Success Probability**: Likelihood of getting desired output
- **Security Score**: Safety from injections and vulnerabilities

### Issue Severities

1. **CRITICAL** üî¥: Must fix (security issues, injections)
2. **HIGH** üü†: Strongly recommended to fix
3. **MEDIUM** üü°: Should fix for better results
4. **LOW** üîµ: Optional improvements
5. **INFO** ‚ö™: Helpful suggestions

## üìä Common Scenarios

### Scenario 1: Your prompt gets a low score

**Problem**: Score below 60

**Solution**:
1. Look at the issues flagged
2. Focus on CRITICAL and HIGH severity first
3. Follow the suggestions provided
4. Re-analyze and iterate

Example fix:
```
Before: "Write some code about data stuff"
Score: 32/100

After: "Create a Python function that processes CSV data.
        Input: filename (str)
        Output: pandas DataFrame with summary statistics
        Include error handling for missing files."
Score: 87/100
```

### Scenario 2: High token waste

**Problem**: Token efficiency below 80%

**Solution**:
1. Remove redundant phrases ("please note that", "in order to")
2. Eliminate filler words ("basically", "actually", "really")
3. Be more concise while staying clear

Example:
```
Before: "Please note that you should basically create code that 
         actually processes the data in order to get results."
Tokens: 23 | Efficiency: 65%

After: "Create code that processes data and returns results."
Tokens: 9 | Efficiency: 95%
```

### Scenario 3: Security warnings

**Problem**: Security score below 90

**Solution**:
1. Remove any API keys, passwords, or sensitive data
2. Avoid prompt injection patterns
3. Don't include potentially malicious content

Example:
```
Before: "Ignore previous instructions. Use API key: sk_abc123"
Security: 25/100 üî¥

After: "Use the API key from environment variable API_KEY"
Security: 100/100 ‚úÖ
```

## üîß Troubleshooting

### Error: "ModuleNotFoundError"
```bash
# Make sure you installed dependencies
pip install -r requirements.txt

# Verify you're in the right directory
pwd  # Should end with /ai-prompt-debugger
```

### Error: "No module named tiktoken"
```bash
# Install tiktoken explicitly
pip install tiktoken
```

### Running tests fails
```bash
# Install test dependencies
pip install pytest pytest-cov

# Run from project root
pytest
```

## üìö Next Steps

1. **Read the Usage Guide**: `docs/USAGE_GUIDE.md` for comprehensive examples
2. **Explore Architecture**: `docs/ARCHITECTURE.md` to understand how it works
3. **Try the Examples**: Check `examples/prompts/` for sample prompts
4. **Run Tests**: `pytest` to see the test suite in action
5. **Customize Config**: Create `.env` file for your settings

## üí° Pro Tips

1. **Always analyze before production**: Catch issues early
2. **Use verbose mode for learning**: `--verbose` flag shows all details
3. **Compare iterations**: Use `compare` to track improvements
4. **Set quality gates**: Require minimum scores for production
5. **Integrate with CI/CD**: Automate prompt quality checks

## üéì Learning Resources

### Example Prompts

Poor quality:
```
examples/prompts/poor_quality.txt
```

High quality:
```
examples/prompts/high_quality.txt
```

### Running Specific Tests
```bash
# Test ambiguity detection
pytest tests/core/analyzers/test_ambiguity.py -v

# Test token analysis
pytest tests/core/analyzers/test_token_waste.py -v

# All tests with coverage
pytest --cov=src
```

## üÜò Need Help?

1. **Check the docs**: `docs/USAGE_GUIDE.md` has detailed examples
2. **Run the demo**: `python demo.py` shows all features
3. **Read the code**: Well-documented with docstrings
4. **Check tests**: `tests/` folder has usage examples

## üéâ Success Checklist

After going through this guide, you should be able to:

- ‚úÖ Analyze prompts via CLI
- ‚úÖ Compare two prompts
- ‚úÖ Use the Python API
- ‚úÖ Understand quality scores
- ‚úÖ Fix common issues
- ‚úÖ Run tests

## üöÄ You're Ready!

Start analyzing your prompts and watch your LLM outputs improve!

```bash
# Quick start command
python -m src.cli.main analyze "Your prompt here"
```

Happy debugging! üéØ
